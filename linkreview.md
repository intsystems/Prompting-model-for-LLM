# LinkReview

Here we have collected info about all the works that may be useful for writing our paper.

> [!NOTE]
> Although we tried to make this version the final one, some changes will still be happening.

### Soft Prompting
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| Dynamic Prompting: A Unified Framework for Prompt Tuning | 2023 | Xianjun Yang | [paper](https://arxiv.org/pdf/2303.02909) | [GitHub](https://github.com/Xianjun-Yang/DPT.) | Статья представляет новый подход "dynamic prompting", который является улучшением традиционного "soft prompting". В отличие от фиксированных размеров вспомогательных эмбеддингов в soft prompting, dynamic prompting позволяет динамически оптимизировать как содержание, так и длину промпта. Это дает большую гибкость в адаптации языковой модели к целевой задаче, обеспечивая более высокое качество результата. |
| Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners | 2022 | Ningyu Zhang Luoqiu Li | [paper](https://arxiv.org/pdf/2108.13161) | - | Предлагается собственный подход к оптимизации soft промптов, в котором используются специальные маски. Эти маски позволяют обучать модель, которая способна выбирать ключевые слова из промпта и использовать их для более эффективной адаптации языковой модели к целевой задаче. |
| Prefix-tuning: Optimizing continuous prompts for generation | 2021 | Xiang Lisa Li and Percy Liang | [paper](https://aclanthology.org/2021.acl-long.353) | - | Fine-tune не для всей предобученной языковой модели, а для её промптов. |
| Late prompt tuning: A late prompt could be better than many prompts | 2022 | Xiangyang Liu | [paper](https://api.semanticscholar.org/CorpusID:253018816) | - | Умная вставка промптов не в начало обучения, а в середину. |
| The Power of Scale for Parameter-Efficient Prompt Tuning | 2021 | Brian Lester, Rami Al-Rfou, Noah Constant | [paper](https://aclanthology.org/2021.emnlp-main.243/) | - | In this paper, authors propose prompt tuning as a simplification for adapting language models. For this it is necessary to freeze the entire pre-trained model and only allow an additional k tunable tokens per downstream task to be prepended to the input text. This “soft prompt” is trained end-to-end and can condense the signal from a full labeled dataset, allowing method to outperform few-shot prompts and close the quality gap with model tuning the same time, since a single pre-trained model is recycled for all downstream tasks, the efficient serving benefits of frozen models are retained. Authors show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient “prompt ensembling.” |
| XPROMPT: Exploring the Extreme of Prompt Tuning | 2022 | Fang Ma, Chen Zhang, Lei Ren, Jingang Wang, Qifan Wang, Wei Wu, Xiaojun Quan, Dawei Song | [paper](https://aclanthology.org/2022.emnlp-main.758/) | - | The fine-tuning is parameter-inefficient for large scale PLMs due to the fact that the memory footprint is proportional to the number of trainable parameters whose gradients and optimizer states need to be stored. Prompt-Tuning has been proposed to address this issue by prepending a soft prompt to the input and only updating the parameters of prompt tokens during tuning. However, there is a large performance gap between prompt tuning and fine-tuning for models of small scales. This paper fill that gap, from the perspective of the lottery tickets hypothesis. Essentially, lottery tickets hypothesis states that an over-parameterized network contains a sub-network that, when initialized and trained in isolation, can match or exceed the test accuracy of the original network after training for at most the same number of iterations. |
| The Power of Scale for Parameter-Efficient Prompt Tuning | 2021 | Katherine Lee, Orhan Firat, Ashish Agarwal, Clara Fannjiang, David Sussillo | [paper](https://arxiv.org/abs/2104.08691) | [Github](https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#lm-adapted-t511lm100k) | Классическая статья по soft prompting'у. Описывается подход, показывается его эффективность, многие дальнейшие работы основываются на ней. |
| Learning How to Ask: Querying LMs with Mixtures of Soft Prompts | 2021 | Guanghui Qin, Jason Eisner | [paper](https://arxiv.org/abs/2104.06599) | [Github](https://github.com/hiaoxui/soft-prompts) | Для каждой задачи оптимизируется смесь подсказок, чтобы определить наиболее эффективные. Результаты показывают, что этот подход значительно превосходит предыдущие методы, демонстрируя, что имплицитные фактические знания в языковых моделях ранее недооценивались. При этом знания можно эффективно извлекать даже при случайной инициализации подсказок. |

---

### Soft + RL
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| RLPROMPT: Optimizing Discrete Text Prompts with Reinforcement Learning | 2022 | Mingkai Deng | [paper](https://arxiv.org/pdf/2205.12548) | [GitHub](https://github.com/mingkaid/rl-prompt) | Предлагают использовать RL для дискретных промптов, в качестве награды используют z-score. Сэмплируют батч промптов для входа x, считают награду для них, потом считают z-score, вышло хуже чем тюнить, но лучше чем остальные подходы и плюс к этому почти без вычислительных ресурсов. |
| TEMPERA: Test-Time Prompting via Reinforcement Learning | 2022 | Xianjun Yang, Wei Cheng, Xujiang Zhao | [paper](https://arxiv.org/abs/2211.11890) | [Github](https://github.com/tianjunz/TEMPERA) | Утверждают, что побили RLPromt и AutoPromt |

---

### Soft -> Hard prompts
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| Soft prompting might be a bug, not a feature | 2023 | Luke Bailey | [paper](https://openreview.net/forum?id=MHWDdMEJ5s#all) | - | Потенциальная уязвимость soft prompts. Почему лучше работать с hard prompt. |
| Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts | 2022 | Daniel Khashabi, Xinxi Lyu, Sewon Min, Lianhui Qin, Kyle Richardson, Sean Welleck, Hannaneh Hajishirzi, Tushar Khot, Ashish Sabharwal, Sameer Singh, Yejin Choi | [paper](https://aclanthology.org/2022.naacl-main.266/) | - | Recent work has shown the surprising power of continuous prompts to language models for controlled generation and for solving a wide range of tasks. Despite these successes, the resulting continuous prompts are not easy to interpret. Authors investigate the Prompt Waywardness hypothesis, a surprising disconnect between the intended behavior of continuous prompts and their nearest-neighbor discrete (language) representations. In particular, it is showen that one can find continuous prompts that perform a desired task while, at the same time, project to any given target text. This indicates the problem of little correspondence between continuous prompts and their discrete interpretation. A single discrete prompt can correspond to only one continuous prompt through its embedding, while the reverse does not hold. |

---

### Hard Prompting
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery | 2023 | Yuxin Wen, Neel Jain, John Kirchenbauer | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/a00548031e4647b13042c97c922fadf1-Paper-Conference.pdf) | [GitHub](https://github.com/YuxinWenRick/hard-prompts-made-easy) | Learning hard prompts for image generation using continuous optimization. The scheme builds on existing gradient reprojection schemes for optimizing text. Берут непрерывные промпты и на каждом шагу проецируют на дискретное пространство, затем оптимизируют градиентым спуском как непрерывные. |
| How Hard Can It Prompt? Adventures in Cross-model Prompt Transferability | 2024 | Lola Solovyeva | [paper](https://essay.utwente.nl/103206/1/Solovyeva_MA_EEMCS.pdf) | [GitHub]() | Discretizing soft prompts by leveraging cosine similarity between the embeddings of soft and hard tokens. Algorithm designed to identify a set of hard tokens using gradients obtained through the tuning of soft prompts. Testing the transferability of the derived hard prompts between different models. Написано примерно то же, что и в предыдущей статье, но в виде более подробной книжки с усложнением алгоритма из статьи выше. |
| Automatic Prompt Optimization with “Gradient Descent” and Beam Search | 2023 | R Pryzant, D Iter | [paper](https://aclanthology.org/2023.emnlp-main.494.pdf) | - | Статья предлагает динамическую оптимизацию промптов в многошаговом процессе, используя градиентный спуск и beam search. Авторы разработали собственный непараметрический алгоритм, объединяющий эти два подхода, что позволяет эффективно оптимизировать содержание и длину входного промпта. Таким образом, предлагаемый метод dynamic prompting дает более гибкие возможности для адаптации языковой модели к конкретной задаче по сравнению с традиционным soft prompting. |
| Improving Text Embeddings with Large Language Models | 2024 | Liang Wang, Nan Yang, Xiaolong Huang, Linjun Yang, Rangan Majumder | [paper](https://arxiv.org/pdf/2401.00368) | - | Приведены ресурсы для датасетов и моделей. В самой статье объединяются подходы оптимизации промпта и PEFT, то есть fine-tuning'а моделей. |

---

### Hallucinations
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples | 2022 | Jia-Yu Yao Kun-Peng Ning | [paper](https://arxiv.org/pdf/2310.01469) | [Github](https://github.com/PKU-YuanGroup/Hallucination-Attack) | В статье рассматриваются галлюцинации. Показываается, что галлюцинации возникают не из-за неправильного обучения модели, а заложены в архитектуре трансформера, то есть для любой LLM можно сгенерировать prompt, на котором модель будет галлюцинировать. Далее в статье рассматривают способы дообучения для больб с галлюцинациями. Рассматривается генерация propmt'ов, на который модели обычно галлюцинируют (2 типа: когда плохо заложен смысл и когда подается бред на вход). Создается вспомогательная модель (Hallucination-Attack) модель, которая генерирует такие propmpt'ы и показывается, как можно дообучать модель для борьбы с этим. |
| A Mathematical Investigation of Hallucination and Creativity in GPT Models | 2023 | Minhyeok Lee | [paper](https://www.mdpi.com/2227-7390/11/10/2320) | - | Авторы вводят строгие определения и метрики для измерения галлюцинаций и креативности, основанные на теории вероятностей и теории информации. Используя параметрическое семейство GPT-моделей, они характеризуют баланс между галлюцинациями и креативностью и находят оптимальную точку, максимизирующую производительность модели на различных задачах. Работа предлагает новую математическую основу для понимания природы и последствий галлюцинаций в GPT-моделях, что открывает перспективы для дальнейших исследований в области больших языковых моделей. |
| SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models | 2023 | Potsawee Manakul, Adian Liusie, Mark J. F. Gales | [paper](https://arxiv.org/abs/2303.08896) | [Github](https://github.com/potsawee/selfcheckgpt) | Работа предлагает подход "SelfCheckGPT" для проверки фактичности ответов больших языковых моделей, таких как GPT-3, без использования внешних баз данных. SelfCheckGPT основан на идее, что если модель обладает знаниями по определённой теме, то её стохастически сгенерированные ответы будут последовательными; в то время как для сгенерированных галлюцинаций ответы будут противоречивыми. Авторы демонстрируют, что предлагаемый подход превосходит существующие методы в задачах детектирования нефактических предложений и оценки фактичности текстовых отрывков. |
| Sources of Hallucination by Large Language Models on Inference Tasks | 2023 | Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini, Mark Johnson, Mark Steedman | [paper](https://arxiv.org/abs/2305.14552) | [Github](https://github.com/Teddy-Li/LLM-NLI-Analysis) | Работа исследует способности больших языковых моделей (LLMs) к задаче "естественного языкового вывода" (NLI), важной для многих прикладных задач. Авторы проводят контролируемые эксперименты с различными LLM (LLaMA, GPT-3.5, PaLM) и выявляют два основных источника галлюцинаций в генеративных моделях: 1) Модели склонны ложно определять гипотезы как следующие из посылок, если гипотезы встречались в данных обучения, независимо от содержания посылок. 2) Модели также демонстрируют предвзятость, если предикат гипотезы более распространен в данных обучения, чем предикат посылки. Авторы показывают, что LLM значительно хуже справляются с тестовыми примерами NLI, не соответствующими этим систематическим смещениям, и предлагают их в качестве ценного контроля для будущей оценки LLM. |
| Hallucinations in Neural Machine Translation | 2019 | Katherine Lee, Orhan Firat, Ashish Agarwal, Clara Fannjiang, David Sussillo | [paper](https://openreview.net/forum?id=SkxJ-309FQ) | [Github](https://github.com/tensorflow/nmt) | Работа изучает проблему "галлюцинаций" в нейронных системах машинного перевода (NMT), когда они генерируют совершенно отвязанные от исходного текста переводы. Авторы описывают метод генерирования таких галлюцинаций и показывают, что они возникают во многих вариациях NMT-архитектур. Исследованы подходы для уменьшения частоты галлюцинаций, в том числе аугментация данных, которая значительно снижает их частоту. Проведен анализ сетей, порождающих галлюцинации, выявлен характерный "почерк" в матрицах внимания и скрытых состояниях декодера. |

---

### Model-Agnostic Meta-Learning
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks | 2017 | Chelsea Finn | [paper](https://proceedings.mlr.press/v70/finn17a/finn17a.pdf) | - | [Simple explaination](https://interactive-maml.github.io/maml.html) На маленьком датасете под конкретную задачу эмпиристически известно, что тюнится плохо. Берут задачи, схожие с решаемой, считаем что это из одного распределения. Сэмплируем батч из каждой таски, делаем шаг градиентного спуска для каждой задачи, и получаем обновленные веса модели (или её изменяемой части) для каждой задачи, и потом делаем шаг градиентного спуска, состоящим из градиентов по каждой таске, но в этом градиенте обновленные веса для каждой таске. То есть получается более обобщенный градиент, так как градиент берется по всем задачам и плюс к этому градиент уже подтюнился под каждую из задач. |
| Probabilistic Model-Agnostic Meta-Learning | 2018 | Chelsea Finn, Kelvin Xu, Sergey Levine | [paper](https://arxiv.org/pdf/2303.02909) | - | Предлагается метод метаобучения для решения задачи обучения на небольшом количестве данных. Вместо одной модели, обучается распределение моделей, что позволяет учитывать неоднозначность данных. Метод основан на MAML и использует вариационный подход. Результаты показывают, что подход позволяет генерировать правдоподобные классификаторы и регрессоры для неоднозначных задач. |
| How to train your MAML | 2019 | Antreas Antoniou, Harri Edwards, Amos Storkey | [paper](https://www.research.ed.ac.uk/en/publications/how-to-train-your-maml) | - | В статье изучаются подходы по улучшению классического maml. |

---

### Dataset
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS | 2024 | Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han | [paper](https://arxiv.org/pdf/2211.01910) | [Github](https://github.com/keirp/automatic_prompt_engineer) | Проведен анализ способностей LLM генерировать промпты, показано, что такой подход хороший. |
| Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference | 2021 | Timo Schick, Hinrich Schutze | [paper](https://arxiv.org/pdf/2001.07676) | [GitHub](https://github.com/timoschick/pet) | Собрали датасет с лучшими промптами для llm-ок |
| OpenPrompt: An Open-source Framework for Prompt-learning | 2021 | Ning Ding | [paper](https://arxiv.org/pdf/2111.01998) | [GitHub](https://github.com/thunlp/OpenPrompt) | Фремворк для генерации промптов |
| DART: Open-Domain Structured Data Record to Text Generation | 2019 | Linyong Nan, Dragomir Radev, Rui Zhang | [paper](https://arxiv.org/pdf/2007.02871) | [Github](https://github.com/Yale-LILY/dart) | Генерация промптов-триплетов из текста |
| GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding | 2018 | Alex Wang, Amanpreet Singh, Julian Michael | [paper](https://aclanthology.org/W18-5446.pdf) | - | На GLUE все любят сравнивать, как хорошо выходят оптимальные промпты (еще есть SuperGlue |

---

### Unified Prompts
| Title | Year | Authors | Paper | Supplemenntary | Summary |
| :--- | ---: | :--- | :--- | :--- | :--- |
| LLM-Informed Discrete Prompt Optimization | 2024 | Zeeshan Memon | [paper](https://openreview.net/pdf?id=d0jQuZe6k0) | [Presentation](https://www.youtube.com/watch?v=MuRa3tlyzq8) | Это работа является ключевой для нашего исследование. В ней авторы разбивают обучение prompt'ов на 2 части: первая часть общая для всех LLM, в ней подразумевается наличие датасета с простыми prompt'ами и улучшенными, чтобы легкий Backbone затюнился лучше сэмплировать хорошие подсказки. Вторая часть обучения проводится для каждой LLM отдельно, в ней MLP и HEAD дообучаются для конкретной LLM для генерации ключевых слов. Авторы утверждают, что у каждой LLM есть набор ключевых слов, использование которых может существенно улучшить prompt'ы и, соответственно, ответы LLM. |
| UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation | 2023 | Daixuan Cheng Shaohan Huang | [paper](https://arxiv.org/abs/2303.08518) | [Github]( https://github.com/microsoft/LMOps) |  |
| Learning to Transfer Prompts for Text Generation | 2022 | Junyi Li, Tianyi Tang, Jian-Yun Nie | [paper](https://arxiv.org/abs/2205.01543) | - |  |

---



